# Vector configuration for log shipping

# Data directory for Vector's state
data_dir = "/var/lib/vector"

# Source: Collect logs from Docker containers
[sources.docker_logs]
type = "docker_logs"
# Optionally filter by container name/label
# include_containers = ["my-app-*"]

# Source: Collect logs from files (if not using Docker)
[sources.file_logs]
type = "file"
include = ["/var/log/apps/*.log"]
read_from = "end"

# Transform: Parse JSON logs and format for Locog API
[transforms.parse_and_enrich]
type = "remap"
inputs = ["docker_logs", "file_logs"]
source = '''
  # Parse JSON from log message
  parsed = {}
  if is_string(.message) {
    parsed, err = parse_json(.message)
    if err != null {
      # If not JSON, treat the whole message as a plain log
      parsed = {
        "message": .message,
        "level": "INFO"
      }
    }
  }

  # Construct output with only Locog API fields
  . = {
    "timestamp": parsed.timestamp ?? .timestamp ?? now(),
    "service": parsed.service ?? .container_name ?? "unknown",
    "level": parsed.level ?? "INFO",
    "message": parsed.message ?? parsed.msg ?? "no message",
    "host": parsed.host ?? get_hostname!(),
  }

  # Add metadata if present (optional field)
  if exists(parsed.metadata) {
    .metadata = parsed.metadata
  }
'''

# Sink: Send to log collector service
[sinks.log_collector]
type = "http"
inputs = ["parse_and_enrich"]
uri = "http://locog:5081/api/ingest"
encoding.codec = "json"

# Batch settings for better performance
batch.max_bytes = 1048576  # 1MB
batch.max_events = 100
batch.timeout_secs = 5

# Retry settings
buffer.type = "disk"
buffer.max_size = 268435488  # 256MB buffer
buffer.when_full = "drop_newest"

# Health check configuration
healthcheck.enabled = true
